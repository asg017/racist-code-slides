import {Cite, Appear} from 'spectacle';
import Number from './components/Number.jsx';
import Title from './components/Title.jsx';
import Name from './components/Name.jsx';
import {aoc, saavedra, food, gerry} from './assets.js'
import QuotePic from './components/QuotePic.jsx';
import Site from './components/Site.jsx'
import {darkComponents} from './slides.js';

# **5** ways to write **racist code**
<Name>Alex Garcia</Name>

<Site/>

---
<Title number={5}>Use racist data</Title>

- data driven decisions with racist data means racist decisions

## Predictive Policing

[Maricopa county, many others](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3333423)

[microsoft Tay](https://www.theverge.com/2016/3/25/11306566/microsoft-racist-tay-ai-twitter-chatbot-apology)

<Site/>

---

<Title number={4}>Don't use diverse data</Title>

- data driver decisions

[FaceApp: White is hot](https://techcrunch.com/2017/04/25/faceapp-apologises-for-building-a-racist-ai/)

[Amazon Reckognition](https://medium.com/@Joy.Buolamwini/response-racial-and-gender-bias-in-amazon-rekognition-commercial-ai-system-for-analyzing-faces-a289222eeced)

[gender data gap](https://amp.theguardian.com/lifeandstyle/2019/feb/23/truth-world-built-for-men-car-crashes?CMP=share_btn_tw&__twitter_impression=true)

<Site/>

---

<Title number={3}>Accidentally</Title>

- Race is *deeply* embedded into many aspects of our life

### Black people in UK 21 times more likely to have university applications
investigated, figures show

> Fraud and similarity detection software, as well as input from universities,
are used when deciding whether an application needs investigating.

[Source](https://www.independent.co.uk/news/education/education-news/uk-black-students-university-applications-investigation-more-likely-ucas-figures-nus-labour-a8314496.html)

<Site/>

---

<Title number={3}>Accidentally</Title>


[Uber's accidental redlining](https://twitter.com/rouge8/status/781279125596241920)

[Same but for seattle](https://medium.com/@SherylCababa/i-combined-the-map-for-seattle-uberhop-with-a-racial-segregation-map-sorry-brown-people-9d756168c8b9)

[Amazon accidental redlining](https://www.bloomberg.com/graphics/2016-amazon-same-day/)


---

<Title number={2}>Use magic black boxes üßôüèº‚Äç‚ôÇÔ∏è</Title>

- Package creators may not have considered racial bias
- Is the package really appropriate for your project?


`pip install`, `npm install`, `packages.install("")`

```r
library(tweetbotornot)
users <- c("realdonaldtrump", "netflix_bot")

\

data <- tweetbotornot(users)

```
[Snapchat Giphy](https://techcrunch.com/2018/03/09/snapchat-removes-giphy-feature-due-to-racial-slur-gif/)

[jewish slur](https://www.nytimes.com/2018/08/30/business/jewtropolis-map-new-york-snapchat.html)

<Site/>

---

```python
text_to_sentiment("Let's go get Italian food")
2.0429166109408983
text_to_sentiment("Let's go get Chinese food")
1.4094033658140972
text_to_sentiment("Let's go get Mexican food")
0.38801985560121732
```

|name|sentiment|group
|-|-|-
|mohammed|0.834974|Arab/Muslim
|terryl|-2.858010|Black
|alya|3.916803|Arab/Muslim
|jos√©|0.432956|Hispanic
|luciana|1.086073|Hispanic
|hank|0.391858|White
|megan|2.158679|White
```

Source: [Robyn Speer](https://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/)

---

<Title number={1}>Think code has no bias</Title>

<QuotePic quote={
  <span>
    ‚ÄúAlgorithms are still made by human beings, and those algorithms are still pegged to basic human assumptions.
    {' '}<b style={{fontSize:'1.5rem'}}>They‚Äôre just automated assumptions</b>.‚Äù
  </span>}
pic={aoc}
align="left"
source={{link:"https://slate.com/news-and-politics/2019/02/aoc-algorithms-racist-bias.html", text:'Slate'}}
quoter="Alexandria Ocasio-Cortez"/>

-

<QuotePic quote={<span>‚ÄúSocialist Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms,
{' '}<b style={{fontSize:'1.5rem'}}>which are driven by math,</b>{' '}
are racist‚Äú</span>}
pic={saavedra}
align="right"
source={{link:"https://twitter.com/RealSaavedra/status/1087627739861897216", text:'Twitter @RealSaavedra'}}
quoter="Ryan Saavedra of Daily Wire"
appear={1}/>

<Site/>

---

<Title number={1}>Think code has no bias</Title>

<QuotePic quote={<span>
‚ÄúUsing machine learning, a subtype of artificial intelligence, the billions of data points were analyzed to see what drove the glucose response to specific foods for each individual.
{' '}<b style={{fontSize:'1.5rem'}}>In that way, an algorithm was built without the biases of the scientists.</b>‚Äù
</span>}
pic={food}
align="left"
source={{link:"https://www.nytimes.com/2019/03/02/opinion/sunday/diet-artificial-intelligence-diabetes.html?", text:'NY Times Opinion piece'}}
quoter="Eric Topol"
appear={0}/>

<Site/>

---

<Title number={1}>Think code has no bias</Title>

<QuotePic quote={<span>
‚ÄúThe big advantage this has is that it could completely take away gerrymandering.
{' '}<b style={{fontSize:'1.5rem'}}>The computer has no bias. </b>
And if you only care about population distribution, then
{' '}<b style={{fontSize:'1.5rem'}}>there's no way to program bias into it.</b>
‚Äù
</span>}
pic={gerry}
align="right"
source={{
  link:"https://www.reddit.com/r/politics/comments/5s0mcz/politics_are_a_mess_lets_hand_it_over_to_software/ddbkd71",
  text:'/r/politics (+193)'
}}
quoter="/u/FunkyTown313"
appear={0}/>

notes: outated data, 2020 census data that included immigration question, assumptions on distribution that work in downtown LA but not in coachella

<Site/>

---

# Final thoughts
- Don't assume your data is free of bias
- Audit your 3rd party packages or models
- Remember biased algorithms *are* possible

üëãüèº

<Site/>
